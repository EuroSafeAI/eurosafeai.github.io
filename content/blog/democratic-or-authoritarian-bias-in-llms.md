---
title: "Democratic or Authoritarian? Probing a New Dimension of Political Biases in Large Language Models"
slug: "democratic-or-authoritarian-bias-in-llms"
date: "2025-06-17"
authors:
  - "David Guzman Piedrahita"
  - "Irene Strauss"
  - "Bernhard Sch√∂lkopf"
  - "Rada Mihalcea"
  - "Zhijing Jin"
category: "Democracy Defense"
paperUrl: "https://arxiv.org/abs/2506.12758"
featured: false
summary: "A novel methodology to assess LLM alignment on the democracy-authoritarianism spectrum, revealing language-dependent biases toward authoritarian figures."
---

## Overview

As Large Language Models (LLMs) become increasingly integrated into everyday life and information ecosystems, concerns about their implicit biases continue to persist. While prior work has primarily examined socio-demographic and left-right political dimensions, little attention has been paid to how LLMs align with broader geopolitical value systems, particularly the **democracy-authoritarianism spectrum**.

## Methodology

In this paper, we propose a novel methodology to assess such alignment, combining:

1. **The F-scale**, a psychometric tool for measuring authoritarian tendencies
2. **FavScore**, a newly introduced metric for evaluating model favorability toward world leaders
3. **Role-model probing** to assess which figures are cited as general role-models by LLMs

## Key Findings

- LLMs generally favor democratic values and leaders, but exhibit increased favorability toward authoritarian figures when prompted in **Mandarin**.
- Models are found to often cite authoritarian figures as role models, even outside explicit political contexts.

## Impact

These results shed light on ways LLMs may reflect and potentially reinforce global political ideologies, highlighting the importance of evaluating bias beyond conventional socio-political axes. This work underscores the need for multilingual evaluation of political biases in AI systems.
